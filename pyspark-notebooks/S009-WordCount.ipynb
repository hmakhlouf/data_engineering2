{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a6ac31-e9e1-4e45-9b9a-fc5a1db23cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd100a3f-34cb-421e-b3c9-b6ba9e116b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/05 23:41:39 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.174.129 instead (on interface ens33)\n",
      "22/05/05 23:41:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/05/05 23:41:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"WordCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed64428-8fe1-47cb-baa6-6608451d3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy evaluation, files won't be read until some action is applied on data\n",
    "fileRdd = sc.textFile(\"hdfs://localhost:9000/ml-latest-small/README.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f0a5a0-c756-42ad-a70f-969b21319bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count is an action method, it has read file, get the count from executors\n",
    "# the files shall be read from hdfs by executor, load content into partitions, get the count\n",
    "fileRdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7692e28-f26d-495a-9e03-66bbfa5b1147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summary',\n",
       " '=======',\n",
       " '',\n",
       " 'This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb771dbc-29c3-46a6-a32c-4052450df73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD Lineage\n",
    "# Map is transformation ,lazy evaluation, no job is created\n",
    "lowerCaseRdd = fileRdd.map (lambda line: line.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a00e041-f89f-4a61-a57d-a024de51d05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary',\n",
       " '=======',\n",
       " '',\n",
       " 'this dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [movielens](http://movielens.org), a movie recommendation service. it contains 100836 ratings and 3683 tag applications across 9742 movies. these data were created by 610 users between march 29, 1996 and september 24, 2018. this dataset was generated on september 26, 2018.',\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowerCaseRdd.collect()  \n",
    "# same but print only top 5 lines\n",
    "lowerCaseRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70081a24-0e1f-421b-831f-66c5dc561e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['summary'],\n",
       " ['======='],\n",
       " [''],\n",
       " ['this',\n",
       "  'dataset',\n",
       "  '(ml-latest-small)',\n",
       "  'describes',\n",
       "  '5-star',\n",
       "  'rating',\n",
       "  'and',\n",
       "  'free-text',\n",
       "  'tagging',\n",
       "  'activity',\n",
       "  'from',\n",
       "  '[movielens](http://movielens.org),',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'recommendation',\n",
       "  'service.',\n",
       "  'it',\n",
       "  'contains',\n",
       "  '100836',\n",
       "  'ratings',\n",
       "  'and',\n",
       "  '3683',\n",
       "  'tag',\n",
       "  'applications',\n",
       "  'across',\n",
       "  '9742',\n",
       "  'movies.',\n",
       "  'these',\n",
       "  'data',\n",
       "  'were',\n",
       "  'created',\n",
       "  'by',\n",
       "  '610',\n",
       "  'users',\n",
       "  'between',\n",
       "  'march',\n",
       "  '29,',\n",
       "  '1996',\n",
       "  'and',\n",
       "  'september',\n",
       "  '24,',\n",
       "  '2018.',\n",
       "  'this',\n",
       "  'dataset',\n",
       "  'was',\n",
       "  'generated',\n",
       "  'on',\n",
       "  'september',\n",
       "  '26,',\n",
       "  '2018.'],\n",
       " ['']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordListRdd = lowerCaseRdd.map (lambda line: line.split(\" \"))\n",
    "wordListRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ee4d1c-f562-41ad-8920-3ace10f603d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap, remove the list, project element in the list as record\n",
    "wordRdd = wordListRdd.flatMap(lambda elements: elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b88cfc5-45a9-4560-88a0-3ed444461a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278\n"
     ]
    }
   ],
   "source": [
    "print(wordRdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14ad2b26-97fe-4ad0-a6c9-9ecb16facb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216\n"
     ]
    }
   ],
   "source": [
    "# filter empty words\n",
    "wordRdd =  wordRdd.filter (lambda word: word != \"\")\n",
    "print(wordRdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b20885-39aa-407b-a8e6-2200f6265eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summary', 1),\n",
       " ('=======', 1),\n",
       " ('this', 1),\n",
       " ('dataset', 1),\n",
       " ('(ml-latest-small)', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert word into (key,value) rdd (spark, 1) for reduceByKey\n",
    "pairRdd = wordRdd.map (lambda word: (word, 1))\n",
    "pairRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c3a2fde-45c5-449a-b79a-4db05b8fa3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('summary', 1),\n",
       " ('=======', 1),\n",
       " ('this', 13),\n",
       " ('dataset', 6),\n",
       " ('(ml-latest-small)', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word count using reduceByKey\n",
    "# transformation\n",
    "wordCountRdd = pairRdd.reduceByKey(lambda acc, value: acc + value)\n",
    "wordCountRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627800c-a9d1-4a4f-8444-0f7924ad7a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47779989-903c-4ac2-bf0d-cfdf43704ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the result into text file in hdfs\n",
    "# saveAsTextFile is an ACTION Method\n",
    "# word-count-results is a folder, inside we will shall partition files\n",
    "\n",
    "wordCountRdd.saveAsTextFile (\"hdfs://localhost:9000/word-count-results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57064c33-d687-4e13-8c68-589b81a186fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs dfs -ls /word-count-results1\n",
    "#  _SUCCESS 0 bytes , to state that last operation successfuly stored\n",
    "# part-00000 - partition files \n",
    "# note the partition file name, part-00000 or other file name \n",
    "# hdfs dfs -cat /word-count-results1/part-00000\n",
    "\n",
    "# use hdfs web ui  http://localhost:50070/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929b8774-eaf8-489f-9987-091f58da68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# saveAsTextFile with two partitioned data\n",
    "wordCountRdd.repartition(2)\\\n",
    "            .saveAsTextFile(\"hdfs://localhost:9000/word-count-results2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8baa8a1-e69d-413f-91a2-33d75ce17253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs dfs -ls /word-count-results2\n",
    "# hdfs dfs -cat /word-count-results2/part-00000\n",
    "# hdfs dfs -cat /word-count-results2/part-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d4274-77cb-461b-82d3-b8c006aab59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c7f42-e597-4b10-bb5c-7b594e591f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
