{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b16dd21-cbd2-49e1-903b-d6a47e8863bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eda4b4a-cbc6-4195-a073-e70235296ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/11 19:10:56 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.174.129 instead (on interface ens33)\n",
      "22/05/11 19:10:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/05/11 19:10:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/11 19:10:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf()\n",
    "# config.set(\"property\", \"value\")\n",
    "config.setMaster(\"local\").setAppName(\"MovieLens\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# spark Session, entry point for Spark SQL, DataFrame\n",
    "spark = SparkSession.builder\\\n",
    "                    .config(conf=config)\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa010e1-495b-466e-9d4c-05e13f656578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to create schema programatically instead of using inferSchema\n",
    "from pyspark.sql.types import StructType, LongType, StringType, IntegerType, DoubleType\n",
    "# True is nullable, False is non nullable\n",
    "movieSchema = StructType()\\\n",
    "                .add(\"movieId\", IntegerType(), True)\\\n",
    "                .add(\"title\", StringType(), True)\\\n",
    "                .add(\"genres\", StringType(), True)\n",
    "\n",
    "ratingSchema = StructType()\\\n",
    "                .add(\"userId\", IntegerType(), True)\\\n",
    "                .add(\"movieId\", IntegerType(), True)\\\n",
    "                .add(\"rating\", DoubleType(), True)\\\n",
    "                .add(\"timestamp\", LongType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28127026-baf0-4ad9-aa93-c3322bf09699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|  Jumanji (1995)|Adventure|Childre...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read movie data\n",
    "# read using dataframe with defind schema\n",
    "# we can use folder path - all csv in the folder read\n",
    "# use file path, only that file read\n",
    "\n",
    "# spark is session, entry point for data frame/sql\n",
    "\n",
    "movieDf = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .schema(movieSchema)\\\n",
    "                .load(\"hdfs://localhost:9000/ml-latest-small/movies.csv\")\n",
    "\n",
    "movieDf.printSchema()\n",
    "movieDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d38f70-cb1e-4279-9197-1af5f58aaf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "+------+-------+------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingDf = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .schema(ratingSchema)\\\n",
    "                .load(\"hdfs://localhost:9000/ml-latest-small/ratings.csv\")\n",
    "\n",
    "ratingDf.printSchema()\n",
    "ratingDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45516732-f6b8-4e1d-ba66-5149a28bfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9742\n",
      "100836\n"
     ]
    }
   ],
   "source": [
    "print (movieDf.count())\n",
    "print(ratingDf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b48fd65-406a-4acb-acd4-b024c6157ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1, movieId=1, rating=4.0, timestamp=964982703),\n",
       " Row(userId=1, movieId=3, rating=4.0, timestamp=964981247)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingDf.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9a3af0-684a-4396-99fa-bbd8b9189d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|   3.5|\n",
      "|   4.5|\n",
      "|   2.5|\n",
      "|   1.0|\n",
      "|   4.0|\n",
      "|   0.5|\n",
      "|   3.0|\n",
      "|   2.0|\n",
      "|   1.5|\n",
      "|   5.0|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the distinct ratings\n",
    "# show the distinct ratings\n",
    "ratingDf.select(\"rating\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa14ad1d-9bf5-422c-98c2-b4cc988f867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- total_ratings: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:==========================================>           (156 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|movieId|total_ratings|\n",
      "+-------+-------------+\n",
      "|    356|          329|\n",
      "|    318|          317|\n",
      "|    296|          307|\n",
      "|    593|          279|\n",
      "|   2571|          278|\n",
      "|    260|          251|\n",
      "|    480|          238|\n",
      "|    110|          237|\n",
      "|    589|          224|\n",
      "|    527|          220|\n",
      "|   2959|          218|\n",
      "|      1|          215|\n",
      "|   1196|          211|\n",
      "|     50|          204|\n",
      "|   2858|          204|\n",
      "|     47|          203|\n",
      "|    780|          202|\n",
      "|    150|          201|\n",
      "|   1198|          200|\n",
      "|   4993|          198|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# aggregation with groupBy\n",
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "\n",
    "# find the movies by total ratings by userId\n",
    "df = ratingDf\\\n",
    "     .groupBy(\"movieId\")\\\n",
    "     .agg(count(\"userId\").alias(\"total_ratings\"))\\\n",
    "     .sort(desc(\"total_ratings\"))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "624cfaa0-d426-48a5-8ea9-ff0f92d59641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|movieId|avg_rating|\n",
      "+-------+----------+\n",
      "|  33138|       5.0|\n",
      "|    876|       5.0|\n",
      "| 147300|       5.0|\n",
      "|  27373|       5.0|\n",
      "|     53|       5.0|\n",
      "|  25887|       5.0|\n",
      "|  84273|       5.0|\n",
      "| 113829|       5.0|\n",
      "| 173963|       5.0|\n",
      "|  26350|       5.0|\n",
      "|  67618|       5.0|\n",
      "|    148|       5.0|\n",
      "| 157775|       5.0|\n",
      "| 142444|       5.0|\n",
      "|    633|       5.0|\n",
      "|    496|       5.0|\n",
      "|   8911|       5.0|\n",
      "|   5513|       5.0|\n",
      "| 152711|       5.0|\n",
      "| 150554|       5.0|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregation with groupBy\n",
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "\n",
    "# find  average rating by users sorted by desc\n",
    "df = ratingDf\\\n",
    "     .groupBy(\"movieId\")\\\n",
    "     .agg(avg(\"rating\").alias(\"avg_rating\"))\\\n",
    "     .sort(desc(\"avg_rating\"))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc507e31-fef7-4ca5-b084-a81c6feb9ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_ratings: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+\n",
      "|movieId|        avg_rating|total_ratings|\n",
      "+-------+------------------+-------------+\n",
      "|    356| 4.164133738601824|          329|\n",
      "|    318| 4.429022082018927|          317|\n",
      "|    296| 4.197068403908795|          307|\n",
      "|    593| 4.161290322580645|          279|\n",
      "|   2571| 4.192446043165468|          278|\n",
      "|    260| 4.231075697211155|          251|\n",
      "|    480|              3.75|          238|\n",
      "|    110| 4.031645569620253|          237|\n",
      "|    589| 3.970982142857143|          224|\n",
      "|    527|             4.225|          220|\n",
      "|   2959| 4.272935779816514|          218|\n",
      "|      1|3.9209302325581397|          215|\n",
      "|   1196|4.2156398104265405|          211|\n",
      "|     50| 4.237745098039215|          204|\n",
      "|   2858| 4.056372549019608|          204|\n",
      "|     47|3.9753694581280787|          203|\n",
      "|    150| 3.845771144278607|          201|\n",
      "|   1198|            4.2075|          200|\n",
      "|   4993| 4.106060606060606|          198|\n",
      "|   1210| 4.137755102040816|          196|\n",
      "+-------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregation with groupBy\n",
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "\n",
    "# find  the most popular movies, where as rated by many users, at least movies should be rated by 100 users\n",
    "# and the average rating should be at least 3.5 and above\n",
    "# and sort the movies by total_ratings\n",
    "mostPopularMoviesDf = ratingDf\\\n",
    "     .groupBy(\"movieId\")\\\n",
    "     .agg(avg(\"rating\").alias(\"avg_rating\"), count(\"userId\").alias(\"total_ratings\") )\\\n",
    "     .filter( (col(\"total_ratings\") >= 100) & (col(\"avg_rating\") >=3.5) )\\\n",
    "     .sort(desc(\"total_ratings\"))\n",
    "\n",
    "mostPopularMoviesDf.cache() # MEMORY\n",
    "\n",
    "mostPopularMoviesDf.printSchema()\n",
    "mostPopularMoviesDf.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3e0bea-ef20-4d07-bef3-f06709086648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-------------+\n",
      "|movieId|               title|        avg_rating|total_ratings|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|    356| Forrest Gump (1994)| 4.164133738601824|          329|\n",
      "|    318|Shawshank Redempt...| 4.429022082018927|          317|\n",
      "|    296| Pulp Fiction (1994)| 4.197068403908795|          307|\n",
      "|    593|Silence of the La...| 4.161290322580645|          279|\n",
      "|   2571|  Matrix, The (1999)| 4.192446043165468|          278|\n",
      "|    260|Star Wars: Episod...| 4.231075697211155|          251|\n",
      "|    480|Jurassic Park (1993)|              3.75|          238|\n",
      "|    110|   Braveheart (1995)| 4.031645569620253|          237|\n",
      "|    589|Terminator 2: Jud...| 3.970982142857143|          224|\n",
      "|    527|Schindler's List ...|             4.225|          220|\n",
      "|   2959|   Fight Club (1999)| 4.272935779816514|          218|\n",
      "|      1|    Toy Story (1995)|3.9209302325581397|          215|\n",
      "|   1196|Star Wars: Episod...|4.2156398104265405|          211|\n",
      "|     50|Usual Suspects, T...| 4.237745098039215|          204|\n",
      "|   2858|American Beauty (...| 4.056372549019608|          204|\n",
      "|     47|Seven (a.k.a. Se7...|3.9753694581280787|          203|\n",
      "|    150|    Apollo 13 (1995)| 3.845771144278607|          201|\n",
      "|   1198|Raiders of the Lo...|            4.2075|          200|\n",
      "|   4993|Lord of the Rings...| 4.106060606060606|          198|\n",
      "|   1210|Star Wars: Episod...| 4.137755102040816|          196|\n",
      "|    858|Godfather, The (1...|         4.2890625|          192|\n",
      "|    457|Fugitive, The (1993)|3.9921052631578946|          190|\n",
      "|   2028|Saving Private Ry...|4.1462765957446805|          188|\n",
      "|   5952|Lord of the Rings...|4.0212765957446805|          188|\n",
      "|   7153|Lord of the Rings...| 4.118918918918919|          185|\n",
      "|    588|      Aladdin (1992)|3.7923497267759565|          183|\n",
      "|    608|        Fargo (1996)| 4.116022099447513|          181|\n",
      "|   2762|Sixth Sense, The ...| 3.893854748603352|          179|\n",
      "|     32|Twelve Monkeys (a...| 3.983050847457627|          177|\n",
      "|    364|Lion King, The (1...| 3.941860465116279|          172|\n",
      "|    377|        Speed (1994)|3.5292397660818713|          171|\n",
      "|   1270|Back to the Futur...| 4.038011695906433|          171|\n",
      "|   3578|    Gladiator (2000)|3.9382352941176473|          170|\n",
      "|   4306|        Shrek (2001)|3.8676470588235294|          170|\n",
      "|    590|Dances with Wolve...|3.8353658536585367|          164|\n",
      "|    648|Mission: Impossib...| 3.537037037037037|          162|\n",
      "|   4226|      Memento (2000)| 4.122641509433962|          159|\n",
      "|   6539|Pirates of the Ca...| 3.778523489932886|          149|\n",
      "|  58559|Dark Knight, The ...| 4.238255033557047|          149|\n",
      "|    595|Beauty and the Be...|3.7705479452054793|          146|\n",
      "|   1214|        Alien (1979)| 3.969178082191781|          146|\n",
      "|   1036|     Die Hard (1988)|3.8620689655172415|          145|\n",
      "|    165|Die Hard: With a ...|3.5555555555555554|          144|\n",
      "|   1265|Groundhog Day (1993)| 3.944055944055944|          143|\n",
      "|  79132|    Inception (2010)| 4.066433566433567|          143|\n",
      "|   1197|Princess Bride, T...| 4.232394366197183|          142|\n",
      "|   1704|Good Will Hunting...| 4.078014184397163|          141|\n",
      "|   6377| Finding Nemo (2003)|3.9609929078014185|          141|\n",
      "|   1291|Indiana Jones and...| 4.046428571428572|          140|\n",
      "|   1136|Monty Python and ...| 4.161764705882353|          136|\n",
      "|    293|Léon: The Profess...| 4.018796992481203|          133|\n",
      "|   1193|One Flew Over the...| 4.203007518796992|          133|\n",
      "|   3793|        X-Men (2000)| 3.699248120300752|          133|\n",
      "|   4886|Monsters, Inc. (2...| 3.871212121212121|          132|\n",
      "|   1089|Reservoir Dogs (1...| 4.202290076335878|          131|\n",
      "|   1240|Terminator, The (...|3.8969465648854964|          131|\n",
      "|   6874|Kill Bill: Vol. 1...|3.9618320610687023|          131|\n",
      "|   7361|Eternal Sunshine ...|4.1603053435114505|          131|\n",
      "|   1221|Godfather: Part I...|  4.25968992248062|          129|\n",
      "|   2329|American History ...| 4.217054263565892|          129|\n",
      "|     34|         Babe (1995)|        3.65234375|          128|\n",
      "|   1200|       Aliens (1986)|3.9642857142857144|          126|\n",
      "|   1213|   Goodfellas (1990)|              4.25|          126|\n",
      "|   1682|Truman Show, The ...|             3.812|          125|\n",
      "|   8961|Incredibles, The ...|             3.836|          125|\n",
      "|    541| Blade Runner (1982)| 4.100806451612903|          124|\n",
      "|   4995|Beautiful Mind, A...|               4.0|          123|\n",
      "|   1097|E.T. the Extra-Te...|3.7663934426229506|          122|\n",
      "|   5349|   Spider-Man (2002)| 3.540983606557377|          122|\n",
      "|    733|    Rock, The (1996)|3.6404958677685952|          121|\n",
      "|   1206|Clockwork Orange,...| 3.995833333333333|          120|\n",
      "|   2716|Ghostbusters (a.k...|             3.775|          120|\n",
      "|   4973|Amelie (Fabuleux ...| 4.183333333333334|          120|\n",
      "|   5445|Minority Report (...|            3.6375|          120|\n",
      "|   1073|Willy Wonka & the...|3.8739495798319328|          119|\n",
      "|   4963|Ocean's Eleven (2...|3.8445378151260505|          119|\n",
      "|   1527|Fifth Element, Th...|3.7456896551724137|          116|\n",
      "|  33794|Batman Begins (2005)|3.8620689655172415|          116|\n",
      "|   5989|Catch Me If You C...|3.9217391304347826|          115|\n",
      "|   1968|Breakfast Club, T...|3.7787610619469025|          113|\n",
      "|   5418|Bourne Identity, ...|3.8169642857142856|          112|\n",
      "|   3147|Green Mile, The (...| 4.148648648648648|          111|\n",
      "|    349|Clear and Present...|3.6045454545454545|          110|\n",
      "|   3996|Crouching Tiger, ...|3.8363636363636364|          110|\n",
      "|   7438|Kill Bill: Vol. 2...| 3.868181818181818|          110|\n",
      "|    924|2001: A Space Ody...|3.8944954128440368|          109|\n",
      "|   1258| Shining, The (1980)|  4.08256880733945|          109|\n",
      "|   2918|Ferris Bueller's ...|3.8394495412844036|          109|\n",
      "|   4878| Donnie Darko (2001)| 3.981651376146789|          109|\n",
      "|   2115|Indiana Jones and...| 3.638888888888889|          108|\n",
      "|   1208|Apocalypse Now (1...| 4.219626168224299|          107|\n",
      "|   4896|Harry Potter and ...|3.7616822429906542|          107|\n",
      "|  48516|Departed, The (2006)| 4.252336448598131|          107|\n",
      "|   1732|Big Lebowski, The...|3.9245283018867925|          106|\n",
      "|   1923|There's Something...| 3.676190476190476|          105|\n",
      "|  68954|           Up (2009)| 4.004761904761905|          105|\n",
      "|    111|  Taxi Driver (1976)| 4.105769230769231|          104|\n",
      "|    223|       Clerks (1994)| 3.855769230769231|          104|\n",
      "|  60069|       WALL·E (2008)|4.0576923076923075|          104|\n",
      "|    161| Crimson Tide (1995)|3.6359223300970873|          103|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join, inner join \n",
    "# get the movie title for the mostPopularMoviesDf\n",
    "# join mostPopularMoviesDf with movieDf based on condition that mostPopularMoviesDf.movieId == movieDf.movieId\n",
    "\n",
    "popularMoviesDf = mostPopularMoviesDf.join(movieDf, mostPopularMoviesDf.movieId == movieDf.movieId)\\\n",
    "                                     .select(movieDf.movieId, \"title\", \"avg_rating\", \"total_ratings\")\\\n",
    "                                     .sort(desc(\"total_ratings\"))\n",
    "\n",
    "popularMoviesDf.cache()\n",
    "\n",
    "popularMoviesDf.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdbb0c7-edbf-4a73-be8a-42106146e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) ColumnarToRow\n",
      "+- InMemoryTableScan [movieId#23, avg_rating#167, total_ratings#169L]\n",
      "      +- InMemoryRelation [movieId#23, avg_rating#167, total_ratings#169L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(3) Sort [total_ratings#169L DESC NULLS LAST], true, 0\n",
      "               +- Exchange rangepartitioning(total_ratings#169L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#232]\n",
      "                  +- *(2) Filter ((isnotnull(avg_rating#167) AND (total_ratings#169L >= 100)) AND (avg_rating#167 >= 3.5))\n",
      "                     +- *(2) HashAggregate(keys=[movieId#23], functions=[avg(rating#24), count(userId#22)])\n",
      "                        +- Exchange hashpartitioning(movieId#23, 200), ENSURE_REQUIREMENTS, [id=#227]\n",
      "                           +- *(1) HashAggregate(keys=[movieId#23], functions=[partial_avg(rating#24), partial_count(userId#22)])\n",
      "                              +- FileScan csv [userId#22,movieId#23,rating#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://localhost:9000/ml-latest-small/ratings.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<userId:int,movieId:int,rating:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plan should be read from bottom   to up.\n",
    "mostPopularMoviesDf.explain() # print physical plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8548a3-c09a-4f6e-9e98-e768fa4c685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['total_ratings DESC NULLS LAST], true\n",
      "+- Project [movieId#0, title#1, avg_rating#167, total_ratings#169L]\n",
      "   +- Join Inner, (movieId#23 = movieId#0)\n",
      "      :- Sort [total_ratings#169L DESC NULLS LAST], true\n",
      "      :  +- Filter ((total_ratings#169L >= cast(100 as bigint)) AND (avg_rating#167 >= 3.5))\n",
      "      :     +- Aggregate [movieId#23], [movieId#23, avg(rating#24) AS avg_rating#167, count(userId#22) AS total_ratings#169L]\n",
      "      :        +- Relation[userId#22,movieId#23,rating#24,timestamp#25L] csv\n",
      "      +- Relation[movieId#0,title#1,genres#2] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "movieId: int, title: string, avg_rating: double, total_ratings: bigint\n",
      "Sort [total_ratings#169L DESC NULLS LAST], true\n",
      "+- Project [movieId#0, title#1, avg_rating#167, total_ratings#169L]\n",
      "   +- Join Inner, (movieId#23 = movieId#0)\n",
      "      :- Sort [total_ratings#169L DESC NULLS LAST], true\n",
      "      :  +- Filter ((total_ratings#169L >= cast(100 as bigint)) AND (avg_rating#167 >= 3.5))\n",
      "      :     +- Aggregate [movieId#23], [movieId#23, avg(rating#24) AS avg_rating#167, count(userId#22) AS total_ratings#169L]\n",
      "      :        +- Relation[userId#22,movieId#23,rating#24,timestamp#25L] csv\n",
      "      +- Relation[movieId#0,title#1,genres#2] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "InMemoryRelation [movieId#0, title#1, avg_rating#167, total_ratings#169L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   +- *(3) Sort [total_ratings#169L DESC NULLS LAST], true, 0\n",
      "      +- Exchange rangepartitioning(total_ratings#169L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#304]\n",
      "         +- *(2) Project [movieId#0, title#1, avg_rating#167, total_ratings#169L]\n",
      "            +- *(2) BroadcastHashJoin [movieId#23], [movieId#0], Inner, BuildLeft, false\n",
      "               :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#297]\n",
      "               :  +- *(1) Filter isnotnull(movieId#23)\n",
      "               :     +- *(1) ColumnarToRow\n",
      "               :        +- InMemoryTableScan [movieId#23, avg_rating#167, total_ratings#169L], [isnotnull(movieId#23)]\n",
      "               :              +- InMemoryRelation [movieId#23, avg_rating#167, total_ratings#169L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "               :                    +- *(3) Sort [total_ratings#169L DESC NULLS LAST], true, 0\n",
      "               :                       +- Exchange rangepartitioning(total_ratings#169L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#232]\n",
      "               :                          +- *(2) Filter ((isnotnull(avg_rating#167) AND (total_ratings#169L >= 100)) AND (avg_rating#167 >= 3.5))\n",
      "               :                             +- *(2) HashAggregate(keys=[movieId#23], functions=[avg(rating#24), count(userId#22)], output=[movieId#23, avg_rating#167, total_ratings#169L])\n",
      "               :                                +- Exchange hashpartitioning(movieId#23, 200), ENSURE_REQUIREMENTS, [id=#227]\n",
      "               :                                   +- *(1) HashAggregate(keys=[movieId#23], functions=[partial_avg(rating#24), partial_count(userId#22)], output=[movieId#23, sum#179, count#180L, count#181L])\n",
      "               :                                      +- FileScan csv [userId#22,movieId#23,rating#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://localhost:9000/ml-latest-small/ratings.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<userId:int,movieId:int,rating:double>\n",
      "               +- *(2) Filter isnotnull(movieId#0)\n",
      "                  +- FileScan csv [movieId#0,title#1] Batched: false, DataFilters: [isnotnull(movieId#0)], Format: CSV, Location: InMemoryFileIndex[hdfs://localhost:9000/ml-latest-small/movies.csv], PartitionFilters: [], PushedFilters: [IsNotNull(movieId)], ReadSchema: struct<movieId:int,title:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "InMemoryTableScan [movieId#0, title#1, avg_rating#167, total_ratings#169L]\n",
      "   +- InMemoryRelation [movieId#0, title#1, avg_rating#167, total_ratings#169L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- *(3) Sort [total_ratings#169L DESC NULLS LAST], true, 0\n",
      "            +- Exchange rangepartitioning(total_ratings#169L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#304]\n",
      "               +- *(2) Project [movieId#0, title#1, avg_rating#167, total_ratings#169L]\n",
      "                  +- *(2) BroadcastHashJoin [movieId#23], [movieId#0], Inner, BuildLeft, false\n",
      "                     :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#297]\n",
      "                     :  +- *(1) Filter isnotnull(movieId#23)\n",
      "                     :     +- *(1) ColumnarToRow\n",
      "                     :        +- InMemoryTableScan [movieId#23, avg_rating#167, total_ratings#169L], [isnotnull(movieId#23)]\n",
      "                     :              +- InMemoryRelation [movieId#23, avg_rating#167, total_ratings#169L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     :                    +- *(3) Sort [total_ratings#169L DESC NULLS LAST], true, 0\n",
      "                     :                       +- Exchange rangepartitioning(total_ratings#169L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#232]\n",
      "                     :                          +- *(2) Filter ((isnotnull(avg_rating#167) AND (total_ratings#169L >= 100)) AND (avg_rating#167 >= 3.5))\n",
      "                     :                             +- *(2) HashAggregate(keys=[movieId#23], functions=[avg(rating#24), count(userId#22)], output=[movieId#23, avg_rating#167, total_ratings#169L])\n",
      "                     :                                +- Exchange hashpartitioning(movieId#23, 200), ENSURE_REQUIREMENTS, [id=#227]\n",
      "                     :                                   +- *(1) HashAggregate(keys=[movieId#23], functions=[partial_avg(rating#24), partial_count(userId#22)], output=[movieId#23, sum#179, count#180L, count#181L])\n",
      "                     :                                      +- FileScan csv [userId#22,movieId#23,rating#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://localhost:9000/ml-latest-small/ratings.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<userId:int,movieId:int,rating:double>\n",
      "                     +- *(2) Filter isnotnull(movieId#0)\n",
      "                        +- FileScan csv [movieId#0,title#1] Batched: false, DataFilters: [isnotnull(movieId#0)], Format: CSV, Location: InMemoryFileIndex[hdfs://localhost:9000/ml-latest-small/movies.csv], PartitionFilters: [], PushedFilters: [IsNotNull(movieId)], ReadSchema: struct<movieId:int,title:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popularMoviesDf.explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b1916c7-7ca8-4492-bb6b-c022107c6e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write popularMoviesDf to hadoop with header [by default headers shall not be written]\n",
    "# overwrite existing files\n",
    "# 70 plus partitions having approx total of 100 plus records\n",
    "# write 70 plus files into hadoop\n",
    "popularMoviesDf.write.mode(\"overwrite\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .csv(\"hdfs://localhost:9000/most-popular-movies-many-files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "520b1e25-79ad-42f2-b0f3-45c9a0ca0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write popularMoviesDf into single file\n",
    "# coalesce(1) to reduce partitions\n",
    "popularMoviesDf.coalesce(1).write.mode(\"overwrite\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .csv(\"hdfs://localhost:9000/most-popular-movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bd9fa97-8817-41af-9107-68d6a059734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now  read the files back from hdfs \n",
    "# for schema, we try to use inferSchema, let spark to build schema itself\n",
    "# use inferSchema for small data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ca8c7a-a134-4ba3-b8ae-1ac12fbdd4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_ratings: integer (nullable = true)\n",
      "\n",
      "Partitions 3\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|movieId|               title|        avg_rating|total_ratings|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|   1206|Clockwork Orange,...| 3.995833333333333|          120|\n",
      "|   2716|Ghostbusters (a.k...|             3.775|          120|\n",
      "|   4973|Amelie (Fabuleux ...| 4.183333333333334|          120|\n",
      "|   5445|Minority Report (...|            3.6375|          120|\n",
      "|   1089|Reservoir Dogs (1...| 4.202290076335878|          131|\n",
      "|   1240|Terminator, The (...|3.8969465648854964|          131|\n",
      "|   6874|Kill Bill: Vol. 1...|3.9618320610687023|          131|\n",
      "|   7361|Eternal Sunshine ...|4.1603053435114505|          131|\n",
      "|   1208|Apocalypse Now (1...| 4.219626168224299|          107|\n",
      "|   4896|Harry Potter and ...|3.7616822429906542|          107|\n",
      "|  48516|Departed, The (2006)| 4.252336448598131|          107|\n",
      "|    924|2001: A Space Ody...|3.8944954128440368|          109|\n",
      "|   1258| Shining, The (1980)|  4.08256880733945|          109|\n",
      "|   2918|Ferris Bueller's ...|3.8394495412844036|          109|\n",
      "|   4878| Donnie Darko (2001)| 3.981651376146789|          109|\n",
      "|      6|         Heat (1995)| 3.946078431372549|          102|\n",
      "|    778|Trainspotting (1996)|  4.03921568627451|          102|\n",
      "|   1222|Full Metal Jacket...| 4.098039215686274|          102|\n",
      "|   5816|Harry Potter and ...|3.5980392156862746|          102|\n",
      "|    293|Léon: The Profess...| 4.018796992481203|          133|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inferSchema will scan csvs and define data types for  youy schema\n",
    "popularMovies = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .option(\"inferSchema\", True)\\\n",
    "                .load(\"hdfs://localhost:9000/most-popular-movies-many-files\")\n",
    "\n",
    "popularMovies.printSchema()\n",
    "print(\"Partitions\", popularMovies.rdd.getNumPartitions())\n",
    "popularMovies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c886da72-997e-494e-8866-4bfa018972a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_ratings: integer (nullable = true)\n",
      "\n",
      "Partitions 1\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|movieId|               title|        avg_rating|total_ratings|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|    356| Forrest Gump (1994)| 4.164133738601824|          329|\n",
      "|    318|Shawshank Redempt...| 4.429022082018927|          317|\n",
      "|    296| Pulp Fiction (1994)| 4.197068403908795|          307|\n",
      "|    593|Silence of the La...| 4.161290322580645|          279|\n",
      "|   2571|  Matrix, The (1999)| 4.192446043165468|          278|\n",
      "|    260|Star Wars: Episod...| 4.231075697211155|          251|\n",
      "|    480|Jurassic Park (1993)|              3.75|          238|\n",
      "|    110|   Braveheart (1995)| 4.031645569620253|          237|\n",
      "|    589|Terminator 2: Jud...| 3.970982142857143|          224|\n",
      "|    527|Schindler's List ...|             4.225|          220|\n",
      "|   2959|   Fight Club (1999)| 4.272935779816514|          218|\n",
      "|      1|    Toy Story (1995)|3.9209302325581397|          215|\n",
      "|   1196|Star Wars: Episod...|4.2156398104265405|          211|\n",
      "|     50|Usual Suspects, T...| 4.237745098039215|          204|\n",
      "|   2858|American Beauty (...| 4.056372549019608|          204|\n",
      "|     47|Seven (a.k.a. Se7...|3.9753694581280787|          203|\n",
      "|    150|    Apollo 13 (1995)| 3.845771144278607|          201|\n",
      "|   1198|Raiders of the Lo...|            4.2075|          200|\n",
      "|   4993|Lord of the Rings...| 4.106060606060606|          198|\n",
      "|   1210|Star Wars: Episod...| 4.137755102040816|          196|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inferSchema will scan csvs and define data types for  youy schema\n",
    "popularMovies = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .option(\"inferSchema\", True)\\\n",
    "                .load(\"hdfs://localhost:9000/most-popular-movies\")\n",
    "\n",
    "popularMovies.printSchema()\n",
    "print(\"Partitions\", popularMovies.rdd.getNumPartitions())\n",
    "popularMovies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8b59c-df77-4dfb-9325-9889df4fedd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
