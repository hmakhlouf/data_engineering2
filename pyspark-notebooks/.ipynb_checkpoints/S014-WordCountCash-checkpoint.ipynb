{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26432f2-a790-416b-a6cd-d861d9f7a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84d5dcb-d221-428a-bf5f-53d11d1bcd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/06 02:29:03 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.174.129 instead (on interface ens33)\n",
      "22/05/06 02:29:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/05/06 02:29:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/06 02:29:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/06 02:29:05 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/05/06 02:29:05 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/05/06 02:29:05 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/05/06 02:29:05 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"WordsCountCash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfe2393-6719-4d8b-aafc-e97fa736e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bb4a17-ed57-40dd-bd50-8936f3940715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prince dont welcome'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to remove special chars\n",
    "# we will all ascii\n",
    "def to_ascii(text):\n",
    "    import re  # library called regular expresion \n",
    "    output = re.sub(r\"[^a-zA-Z0-9 ]\",\"\",text)\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "#testing the function \n",
    "text = \"prince, don't ;welcome\"\n",
    "to_ascii(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5238371-4ceb-49c9-a0d9-13e201fc29db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isCached  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('chapter', 367),\n",
       " ('i', 4089),\n",
       " ('well', 741),\n",
       " ('prince', 1886),\n",
       " ('so', 1852),\n",
       " ('genoa', 3),\n",
       " ('and', 22082),\n",
       " ('lucca', 2),\n",
       " ('are', 1259),\n",
       " ('now', 1305)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountRdd = sc.textFile(\"hdfs://localhost:9000/books/book-war-and-peace.txt\")\\\n",
    "                 .map (lambda line: to_ascii(line))\\\n",
    "                  .map (lambda line: line.strip().lower())\\\n",
    "                 .map (lambda line: line.split(\" \"))\\\n",
    "                 .flatMap(lambda elements: elements)\\\n",
    "                 .filter (lambda word: word != \"\")\\\n",
    "                 .map (lambda word: (word, 1))\\\n",
    "                 .reduceByKey(lambda acc, value: acc + value)\n",
    "# we are using wordCountRdd first time \n",
    "from pyspark import StorageLevel\n",
    "\n",
    "\n",
    "\n",
    "# wordCountRdd.persist(StorageLevel.MEMORY_AND_DISK) use this command or this one bellow. use either one they give the same results \n",
    "\n",
    "wordCountRdd.cache() # will call persist internally with MEMORY option\n",
    "print(\"isCached \", wordCountRdd.is_cached)\n",
    "wordCountRdd.take(10) # action 1, now result shall be cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28a1dd-df63-4c83-986e-1c99c48cc393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5236fc-054f-451c-8003-7de77a8559b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275a252-87cc-41d5-8d4e-1a8f15ddf1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf92c8e-19b3-4a8f-9dcc-7a4b542b5b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
